{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024d167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3dfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #1: Web Scraping\n",
    "# Web scraping was performed to extract data from the Wikipedia page, making it accessible for analysis.\n",
    "url = \"https://en.wikipedia.org/wiki/Air_quality_index\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the table containing the data\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "data = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2756cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #2 and Step #3 - Removing Headers and Formatting Data:\n",
      "               City      AQI    Category\n",
      "0   Carbon monoxide  8 hours       9 ppm\n",
      "1  Nitrogen dioxide   1 hour    0.12 ppm\n",
      "2             Ozone   1 hour    0.10 ppm\n",
      "3   Sulphur dioxide   1 hour    0.20 ppm\n",
      "4              Lead   1 year  0.50 μg/m3\n"
     ]
    }
   ],
   "source": [
    "# Step #2: Remove Headers and Step #3: Format Data\n",
    "# Headers were removed to eliminate unnecessary titles or labels that could interfere with data analysis.\n",
    "# Data formatting was necessary to standardize data types and formats for consistency and readability.\n",
    "for row in table.find_all('tr')[1:]:\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) >= 3:  # Ensure it's a data row\n",
    "        city = columns[0].get_text(strip=True)\n",
    "        aqi = columns[1].get_text(strip=True)\n",
    "        category = columns[2].get_text(strip=True)\n",
    "        data.append([city, aqi, category])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['City', 'AQI', 'Category'])\n",
    "\n",
    "# Print the DataFrame after Step #2 and Step #3\n",
    "print(\"Step #2 and Step #3 - Removing Headers and Formatting Data:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c44b76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step #5 - Removing Duplicates:\n",
      "               City      AQI    Category\n",
      "0   Carbon monoxide  8 hours       9 ppm\n",
      "1  Nitrogen dioxide   1 hour    0.12 ppm\n",
      "2             Ozone   1 hour    0.10 ppm\n",
      "3   Sulphur dioxide   1 hour    0.20 ppm\n",
      "4              Lead   1 year  0.50 μg/m3\n"
     ]
    }
   ],
   "source": [
    "# Step #5: Find Duplicates\n",
    "# Duplicates were removed to avoid redundant information and maintain a clean dataset.\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Print the DataFrame after Step #5\n",
    "print(\"\\nStep #5 - Removing Duplicates:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e764f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step #6 - Fixing Casing:\n",
      "               City      AQI    Category\n",
      "0   Carbon Monoxide  8 hours       9 ppm\n",
      "1  Nitrogen Dioxide   1 hour    0.12 ppm\n",
      "2             Ozone   1 hour    0.10 ppm\n",
      "3   Sulphur Dioxide   1 hour    0.20 ppm\n",
      "4              Lead   1 year  0.50 μg/m3\n"
     ]
    }
   ],
   "source": [
    "# Step #6: Fix Casing (Converting City names to title case)\n",
    "# Casing was fixed to ensure consistent capitalization of city names and avoid inconsistencies in data.\n",
    "df['City'] = df['City'].str.title()\n",
    "\n",
    "# Print the DataFrame after Step #6\n",
    "print(\"\\nStep #6 - Fixing Casing:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba7df8a",
   "metadata": {},
   "source": [
    "Data wrangling, including web scraping and data cleaning, can raise several ethical implications when dealing with data from sources like Wikipedia. In the context of the provided data source about the Air Quality Index (AQI), some ethical concerns may arise. Firstly, web scraping can potentially put a strain on the website's servers if performed excessively, which may be seen as unethical, as it can disrupt the normal functioning of the site. Ensuring responsible web scraping practices, such as using proper user agents and adhering to scraping policies, is essential. Additionally, data cleaning steps, such as removing duplicates and fixing casing, are generally straightforward. However, if data cleaning involves subjective decisions, there can be concerns about introducing unintentional biases. For example, the decision to title case city names could lead to a Western-centric bias in capitalization, which may not be appropriate for all contexts. It is important to document and justify any data cleaning decisions to maintain transparency and address potential ethical concerns related to bias or data quality. Ultimately, ethical data wrangling should prioritize the accuracy, fairness, and respect for data sources while ensuring that any analysis is conducted responsibly and with full awareness of potential biases and implications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f2ccc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
